---
title: H5视频直播扫盲
date: 2016-05-25 21:04:19
tags:
- 视频直播
- HTML5
categories:
- 615
photos: https://qiniu.nihaoshijie.com.cn/1-1604251R0335K.jpg
---
视频直播这么火，再不学就out了。

为了紧跟潮流，本文将向大家介绍一下视频直播中的基本流程和主要的技术点，包括但不限于前端技术。
<h2><strong>1 H5到底能不能做视频直播？</strong></h2>
当然可以， H5火了这么久，涵盖了各个方面的技术。
<!--more-->
对于视频录制，可以使用强大的<span style="color: #0000cd;">webRTC</span>（Web Real-Time Communication）是一个支持网页浏览器进行实时语音对话或视频对话的技术，缺点是只在PC的chrome上支持较好，移动端支持不太理想。

对于视频播放，可以使用<span style="color: #0000cd;">HLS</span>(HTTP Live Streaming)协议播放直播流，ios和android都天然支持这种协议，配置简单，直接使用video标签即可。

webRTC兼容性：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2010.24.48.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2010.24.48.png" />

video标签播放hls协议视频：
<pre class="lang:default decode:true">&lt;video controls autoplay&gt;  
    &lt;source src="http://10.66.69.77:8080/hls/mystream.m3u8" type="application/vnd.apple.mpegurl" /&gt;  
    &lt;p class="warning"&gt;Your browser does not support HTML5 video.&lt;/p&gt;  
&lt;/video&gt;</pre>
<h2><strong>2 到底什么是HLS协议？</strong></h2>
当简单讲就是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些，前面提到了用于H5播放直播视频时引入的一个<span style="color: #0000cd;">.m3u8</span>的文件，这个文件就是基于HLS协议，存放视频流元数据的文件。

每一个.m3u8文件，分别对应若干个ts文件，这些ts文件才是真正存放视频的数据，m3u8文件只是存放了一些ts文件的配置信息和相关路径，当视频播放时，.m3u8是动态改变的，video标签会解析这个文件，并找到对应的ts文件来播放，所以一般为了加快速度，.m3u8放在web服务器上，ts文件放在cdn上。

.m3u8文件，其实就是以UTF-8编码的m3u文件，这个文件本身不能播放，只是存放了播放信息的文本文件：
<pre>​#EXTM3U                     m3u文件头
#EXT-X-MEDIA-SEQUENCE       第一个TS分片的序列号
#EXT-X-TARGETDURATION       每个分片TS的最大的时长
#EXT-X-ALLOW-CACHE          是否允许cache
#EXT-X-ENDLIST              m3u8文件结束符
#EXTINF                     指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效
mystream-12.ts</pre>
ts文件：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.09.29.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.09.29.png" />

HLS的请求流程是：
<strong>1 http请求m3u8的url
2 服务端返回一个m3u8的播放列表，这个播放列表是实时跟新的，一般一次给出3段数据的url
3 客户端解析m3u8的播放列表，再按序请求每一段的url，获取ts数据流</strong>

简单流程：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.20.29.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.20.29.png" />
<h2><strong>3 HLS直播延时</strong></h2>
当我们知道hls协议是将直播流分成一段一段的小段视频去下载播放的，所以假设列表里面的包含5个TS文件，每个TS文件包含5秒的视频内容，那么整体的延迟就是25秒。因为当你看到这些视频时，主播已经将视频录制好上传上去了，所以时这样产生的延迟。当然可以缩短列表的长度和单个TS文件的大小来降低延迟，极致来说可以缩减列表长度为1，并且TS的时长为1s，但是这样会造成请求次数增加，增大服务器压力，当网速慢时回造成更多的缓冲，所以苹果官方推荐的ts时长时10s，所以这样就会大改有30s的延迟。参考资料：<a href="https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/StreamingMediaGuide/FrequentlyAskedQuestions/FrequentlyAskedQuestions.html" data-cke-saved-href="https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/StreamingMediaGuide/FrequentlyAskedQuestions/FrequentlyAskedQuestions.html">https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/StreamingMediaGuide/FrequentlyAskedQuestions/FrequentlyAskedQuestions.html</a>
<h2><strong>4 视频直播的整个流程是什么？</strong></h2>
当视频直播可大致分为：

<strong>1 视频录制端：一般是电脑上的音视频输入设备或者手机端的摄像头或者麦克风，目前已移动端的手机视频为主。</strong>

<strong>2 视频播放端：可以是电脑上的播放器，手机端的native播放器，还有就是h5的video标签等，目前还是已手机端的native播放器为主。</strong>

<strong>3 视频服务器端：一般是一台nginx服务器，用来接受视频录制端提供的视频源，同时提供给视频播放端流服务。</strong>

简单流程：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.33.20.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2011.33.20.png" />

&nbsp;

&nbsp;
<h2><strong>5 怎样进行音视频采集？</strong></h2>
当首先明确几个概念：

<strong>视频编码：所谓视频编码就是指通过特定的压缩技术，将某个视频格式的文件转换成另一种视频格式文件的方式，我们使用的iphone录制的视频，必须要经过编码，上传，解码，才能真正的在用户端的播放器里播放。</strong>

<strong>编解码标准：视频流传输中最为重要的编解码标准有国际电联的H.261、H.263、H.264，其中HLS协议支持<span style="color: #0000cd;">H.264</span>格式的编码。
音频编码：同视频编码类似，将原始的音频流按照一定的标准进行编码，上传，解码，同时在播放器里播放，当然音频也有许多编码标准，例如PCM编码，WMA编码，AAC编码等等，这里我们HLS协议支持的音频编码方式是<span style="color: #0000cd;">AAC编码</span>。</strong>

下面将利用ios上的摄像头，进行音视频的数据采集，主要分为以下几个步骤：

&nbsp;

<strong>1 音视频的采集，ios中，利用<span style="color: #0000cd;">AVCaptureSession</span>和<span style="color: #0000cd;">AVCaptureDevice</span>可以采集到原始的音视频数据流。
2 对视频进行H264编码，对音频进行AAC编码，在ios中分别有已经封装好的编码库来实现对音视频的编码。
3 对编码后的音、视频数据进行组装封包；
4 建立<span style="color: #0000cd;">RTMP</span>连接并上推到服务端。</strong>

&nbsp;

ps：由于编码库大多使用c语言编写，需要自己使用时编译，对于ios，可以使用已经编译好的编码库。

x264编码：<a href="https://github.com/kewlbear/x264-ios" data-cke-saved-href="https://github.com/kewlbear/x264-ios">https://github.com/kewlbear/x264-ios</a>

faac编码：<a href="https://github.com/fflydev/faac-ios-build" data-cke-saved-href="https://github.com/fflydev/faac-ios-build">https://github.com/fflydev/faac-ios-build</a>

ffmpeg编码：<a href="https://github.com/kewlbear/FFmpeg-iOS-build-script" data-cke-saved-href="https://github.com/kewlbear/FFmpeg-iOS-build-script">https://github.com/kewlbear/FFmpeg-iOS-build-script</a>

关于如果想给视频增加一些特殊效果，例如增加滤镜等，一般在编码前给使用滤镜库，但是这样也会造成一些耗时，导致上传视频数据有一定延时。

简单流程：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2012.07.49.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-23%2012.07.49.png" />
<h2><strong>6 前面提到的ffmpeg是什么？</strong></h2>
和之前的<span style="color: #0000cd;">x264</span>一样，<span style="color: #0000cd;">ffmpeg</span>其实也是一套编码库，类似的还有Xvid，Xvid是基于MPEG4协议的编解码器，x264是基于H.264协议的编码器，ffmpeg集合了各种音频，视频编解码协议，通过设置参数可以完成基于MPEG4,H.264等协议的编解码，demo这里使用的是x264编码库。
<h2><strong>7 什么是RTMP？</strong></h2>
Real Time Messaging Protocol（简称 RTMP）是 Macromedia 开发的一套视频直播协议，现在属于 Adobe。和HLS一样都可以应用于视频直播，区别是RTMP基于flash无法在ios的浏览器里播放，但是实时性比HLS要好。所以一般使用这种协议来上传视频流，也就是视频流推送到服务器。

这里列举一下hls和rtmp对比：

<img src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-25%2010.43.02.png" alt="" data-cke-saved-src="https://qiniu.nihaoshijie.com.cn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-25%2010.43.02.png" />
<h2><strong>8 推流</strong></h2>
简所谓推流，就是将我们已经编码好的音视频数据发往视频流服务器中，一般常用的是使用rtmp推流，可以使用第三方库<strong><a href="https://github.com/ifactorylab/librtmp-iOS" data-cke-saved-href="https://github.com/ifactorylab/librtmp-iOS">librtmp-iOS</a></strong>进行推流，librtmp封装了一些核心的api供使用者调用，如果觉得麻烦，可以使用现成的ios视频推流sdk，也是基于rtmp的，<a href="https://github.com/runner365/LiveVideoCoreSDK" data-cke-saved-href="https://github.com/runner365/LiveVideoCoreSDK">https://github.com/runner365/LiveVideoCoreSDK</a>
<h2><strong>9 推流服务器搭建</strong></h2>
简简单的推流服务器搭建，由于我们上传的视频流都是基于rtmp协议的，所以服务器也必须要支持rtmp才行，大概需要以下几个步骤：

<strong>1 安装一台nginx服务器。</strong>

<strong>2 安装nginx的rtmp扩展，目前使用比较多的是<a href="https://github.com/arut/nginx-rtmp-module" data-cke-saved-href="https://github.com/arut/nginx-rtmp-module">https://github.com/arut/nginx-rtmp-module</a></strong>

<strong>3 配置nginx的conf文件：</strong>
<pre>rtmp {  
  
    server {  
  
        listen 1935;  #监听的端口
  
        chunk_size 4000;  
        
         
        application hls {  #rtmp推流请求路径
            live on;  
            hls on;  
            hls_path /usr/local/var/www/hls;  
            hls_fragment 5s;  
        }  
    }  
}</pre>
<strong>4 重启nginx，将rtmp的推流地址写为rtmp://ip:1935/hls/mystream，其中hls_path表示生成的.m3u8和ts文件所存放的地址，hls_fragment表示切片时长，mysteam表示一个实例，即将来要生成的文件名可以先自己随便设置一个。更多配置可以参考：<a href="https://github.com/arut/nginx-rtmp-module/wiki/" data-cke-saved-href="https://github.com/arut/nginx-rtmp-module/wiki/">https://github.com/arut/nginx-rtmp-module/wiki/</a></strong>

根据以上步骤基本上已经实现了一个支持rtmp的视频服务器了。
<h2><strong>10 在html5页面进行播放直播视频？</strong></h2>
简单来说，直接使用video标签即可播放hls协议的直播视频：
<pre>&lt;video autoplay webkit-playsinline&gt;  
    &lt;source src="http://10.66.69.77:8080/hls/mystream.m3u8" type="application/vnd.apple.mpegurl" /&gt;  
    &lt;p class="warning"&gt;Your browser does not support HTML5 video.&lt;/p&gt;  
&lt;/video&gt;</pre>
需要注意的是，给video标签增加webkit-playsinline属性，这个属性是为了让video视频在ios的uiwebview里面可以不全屏播放，默认ios会全屏播放视频，需要给uiwebview设置allowsInlineMediaPlayback＝YES。业界比较成熟的<a href="http://videojs.com/" data-cke-saved-href="http://videojs.com/">videojs</a>，可以根据不同平台选择不同的策略，例如ios使用video标签，pc使用flash等。
<h2><strong>11 坑点总结</strong></h2>
简根据以上步骤，笔者写了一个demo，从实现ios视频录制，采集，上传，nginx服务器下发直播流，h5页面播放直播视频者一整套流程，总结出以下几点比较坑的地方：

1 在使用AVCaptureSession进行采集视频时，需要实现AVCaptureVideoDataOutputSampleBufferDelegate协议，同时在- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection捕获到视频流，要注意的是didOutputSampleBuffer这个方法不是didDropSampleBuffer方法，后者只会触发一次，当时开始写的是didDropSampleBuffer方法，差了半天才发现方法调用错了。

2 在使用rtmp推流时，rmtp地址要以rtmp://开头，ip地址要写实际ip地址，不要写成localhost，同时要加上端口号，因为手机端上传时是无法识别localhost的。

这里后续会补充上一些坑点，有的需要贴代码，这里先列这么多。
<h2><strong>12 业界支持</strong></h2>
目前，<a href="https://www.qcloud.com/solution/video.html" data-cke-saved-href="https://www.qcloud.com/solution/video.html">腾讯云</a>，百度云，阿里云都已经有了基于视频直播的解决方案，从视频录制到视频播放，推流，都有一系列的sdk可以使用，缺点就是需要收费，如果可以的话，自己实现一套也并不是难事哈。

&nbsp;

demo地址：<a href="https://github.com/lvming6816077/LMVideoTest/" data-cke-saved-href="http://blob/master/LMVideoTest/ViewController.m">https://github.com/lvming6816077/LMVideoTest/</a>